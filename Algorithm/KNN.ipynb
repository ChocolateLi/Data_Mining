{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用KNN实现分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           1       0.78      0.44      0.56        16\n",
      "           2       0.44      0.78      0.56         9\n",
      "\n",
      "    accuracy                           0.71        38\n",
      "   macro avg       0.74      0.74      0.71        38\n",
      "weighted avg       0.77      0.71      0.71        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:,:2]\n",
    "y = iris.target\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=0)\n",
    "# n_neighbors：邻居的数量。\n",
    "# weights：权重计算方式。可选值为uniform与distance。\n",
    "# uniform：所有样本统一权重。\n",
    "# distance：样本权重与距离成反比。\n",
    "knn = KNeighborsClassifier(n_neighbors=3,weights=\"uniform\")\n",
    "knn.fit(X_train,y_train)\n",
    "y_hat = knn.predict(X_test)\n",
    "print(classification_report(y_test,y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 超参数调整\n",
    "网格交叉验证法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 20 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1839s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done  58 out of  80 | elapsed:    3.6s remaining:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  67 out of  80 | elapsed:    3.6s remaining:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  76 out of  80 | elapsed:    3.6s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:    3.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, estimator=KNeighborsClassifier(), n_jobs=-1,\n",
       "             param_grid={'n_neighbors': range(1, 11),\n",
       "                         'weights': ['uniform', 'distance']},\n",
       "             scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "# 定义需要尝试的超参数组合\n",
    "grid = {\"n_neighbors\":range(1,11,1),\"weights\":['uniform','distance']}\n",
    "# estimator：评估器，即对哪个模型调整超参数。\n",
    "# param_grid：需要检验的超参数组合。从这些组合中，寻找效果最好的超参数组合。\n",
    "# scoring：模型评估标准。\n",
    "# n_jobs：并发数量。\n",
    "# cv：交叉验证折数。\n",
    "# verbose：输出冗余信息，值越大，输出的信息越多。\n",
    "gd = GridSearchCV(estimator=knn,param_grid=grid,scoring=\"accuracy\",n_jobs=-1,cv=4,verbose=10)\n",
    "gd.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7946428571428571\n",
      "{'n_neighbors': 9, 'weights': 'uniform'}\n",
      "KNeighborsClassifier(n_neighbors=9)\n"
     ]
    }
   ],
   "source": [
    "# 最好的分值\n",
    "print(gd.best_score_)\n",
    "# 最好的超参数组合\n",
    "print(gd.best_params_)\n",
    "# 使用最好的超参数训练模型\n",
    "print(gd.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           1       0.75      0.38      0.50        16\n",
      "           2       0.41      0.78      0.54         9\n",
      "\n",
      "    accuracy                           0.68        38\n",
      "   macro avg       0.72      0.72      0.68        38\n",
      "weighted avg       0.76      0.68      0.68        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "estimator = gd.best_estimator_\n",
    "y_hat = estimator.predict(X_test)\n",
    "print(classification_report(y_test,y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用KNN回归预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN算法R^2值： 0.509785478689029\n",
      "线性回归算法R^2值： 0.6354638433202122\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.neighbors import KNeighborsRegressor \n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X, y = load_boston(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "knn = KNeighborsRegressor(n_neighbors=3, weights=\"uniform\") \n",
    "knn.fit(X_train, y_train)\n",
    "print(\"KNN算法R^2值：\", knn.score(X_test, y_test))\n",
    "lr = LinearRegression() \n",
    "lr.fit(X_train, y_train)\n",
    "print(\"线性回归算法R^2值：\", lr.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据标准化\n",
    "我们发现，使用KNN算法进行回归，效果比线性回归要差很多，但这并不能证明KNN算法是不如线性回 归的。原因在于，线性回归在训练参数时，不是基于距离进行计算的，因此，即使线性回归各个特征的 量纲（数量级）不同，也不影响最终的拟合效果（权重会不同）。不过，KNN是基于距离计算的，如果 特征之间的量纲不同，在计算时，量纲较大的特征就会占据主导地位，从而算法会忽略量纲较小的特征，这将会对模型性能造成较大的影响。\n",
    "\n",
    "实际上，不只是KNN算法，很多算法对特征的数量级都是敏感的，因此，在使用算法之前，我们最好将 数据集中的特征转换成相同的量纲，从而消除不同量纲对算法造成的负面影响，我们将这个过程称为数 据标准化。实际上，即使特征量纲相同，标准化也不会产生负面影响。\n",
    "\n",
    "常用的标准化方式为均值标准差标准化（StandardScaler）与最小最大值标准化\n",
    "（MinMaxScaler）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "均值标准差标准化 0.6248800677762865\n",
      "最小最大值标准化 0.6177749492293981\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "\n",
    "scaler = [StandardScaler(),MinMaxScaler()]\n",
    "desc = [\"均值标准差标准化\",\"最小最大值标准化\"]\n",
    "for s,d in zip(scaler,desc):\n",
    "    X_train_scale = s.fit_transform(X_train)\n",
    "    X_test_scale = s.transform(X_test)\n",
    "    knn = KNeighborsRegressor(n_neighbors=3,weights=\"uniform\")\n",
    "    knn.fit(X_train_scale,y_train)\n",
    "    print(d,knn.score(X_test_scale,y_test))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 流水线\n",
    "在上例中，我们使用标准化对训练数据进行了转换，然后使用KNN模型对象在转换后的数据上进行拟合。可以说，这是两个步骤。我们虽然可以分别去执行这两个步骤，然而，当数据预处理的工作较多时，可能会涉及更多的步骤（例如多项式扩展，One-Hot编码，特征选择等操作），此时分别执行每个步骤会显得过于繁琐。\n",
    "\n",
    "流水线（Pipeline类）可以将每个评估器视为一个步骤，然后将多个步骤作为一个整体而依次执行，这 样，我们就无需分别执行每个步骤。例如，在上例中，我们就可以将数据标准化与训练模型两个步骤视 为一个整体，一并执行。\n",
    "\n",
    "流水线具有最后一个评估器的所有方法。当通过流水线对象调用方法   时，会执行这样的过程（假设流水线具有n个评估器）：\n",
    "1、如果是fit方法，则会首先对前 n - 1个评估器依次调用fit_transform方法，然后在最后一个评估器上调用 （fit）方法。\n",
    "2、如果是其他方法，则会首先对前 n - 1个评估器依次调用transform方法，然后在最后一个评估器上调用 f方法。\n",
    "\n",
    "例如，当在流水线上调用fit方法时，将会依次在每个评估器上调用fit_transform方法，前一个评估器将 转换之后的结果传递给下一个评估器，直到最后一个评估器调用fit方法为止（最后一个评估器不会调用transform方法）。而当在流水线上调用predict方法时，则会依次在每个评估器上调用transform方\n",
    "法，在最后一个评估器上调用predict方法。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6248800677762865\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "X,y = load_boston(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "#   定义流水线的步骤。类型为一个列表，列表中的每个元素是元组类型，\n",
    "# 格式为：[(步骤名1，评估器1), (步骤名2， 评估器2)，……， (步骤名n, 评估器n) \n",
    "steps = [(\"scaler\", StandardScaler()), (\"knn\", KNeighborsRegressor())] \n",
    "p = Pipeline(steps)\n",
    "#   设置流水线的参数。所有可用的参数，可以通过get_params获取。\n",
    "p.set_params(knn__n_neighbors=3, knn__weights=\"uniform\") \n",
    "p.fit(X_train,y_train)\n",
    "print(p.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
